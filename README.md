# Awesome-AIGC4AEC
Collecting papers about **potential** AIGC applications in the AEC industry.

![Awesome](https://awesome.re/badge.svg) ![Version](https://img.shields.io/badge/Version-1.0-ff69b4.svg) ![LastUpdated](https://img.shields.io/badge/LastUpdated-2024.4-lightgrey.svg) ![Topic](https://img.shields.io/badge/Topic-AIGC--For--AEC--Industry-yellow.svg?logo=github) [![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2FTHUCBIMS%2FAwesome-AIGC4AEC&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false)](https://hits.seeyoufarm.com)

This is an awesome list of **potential** AIGC applications in the AEC industry. Wish it could be helpful for both academia and industry. (Still updating)

Please feel free to pull requests to add new resources or open issues for questions, discussion and collaborations.


## Object Scale

### Mesh Design

### Parametric Design
* How Can Large Language Models Help Humans in Design and Manufacturing? (Arxiv'23) [[Paper]](https://arxiv.org/pdf/2307.14377) 
### Texture Design

* Make-it-Real: Unleashing Large Multimodal Model's Ability for Painting 3D Objects with Realistic Materials (Arxiv'24) [[Project]](https://sunzey.github.io/Make-it-Real/) [[Paper]](https://arxiv.org/pdf/2404.16829) [[Code]](https://github.com/Aleafy/Make_it_Real/)

* MaPa: Text-driven Photorealistic Material Painting for 3D Shapes (SIGGRAPH'24) [[Project]](https://zhanghe3z.github.io/MaPa/) [[Paper]](https://github.com/zhanghe3z/MaPa/releases/download/paper/2024_SIGGRAPH_PaintMat_arxiv.6.pdf)

* DreamPBR: Text-driven Generation of High-resolution SVBRDF with Multi-modal Guidance (Arxiv'24) [[Paper]](https://arxiv.org/pdf/2404.14676)

* FlashTex: Fast Relightable Mesh Texturing with LightControlNet (Arxiv'24) [[Project]](https://flashtex.github.io/) [[Paper]](https://arxiv.org/pdf/2402.13251)

* Paint-it: Text-to-Texture Synthesis via Deep Convolutional Texture Map Optimization and Physically-Based Rendering (CVPR'24) [[Project]](https://kim-youwang.github.io/paint-it) [[Paper]](https://kim-youwang.github.io/media/paint-it/paint-it.pdf) [[Code]](https://github.com/postech-ami/paint-it)

* TextureDreamer: Image-guided Texture Synthesis through Geometry-aware Diffusion (Arxiv'24) [[Project]](https://texturedreamer.github.io/) [[Paper]](https://arxiv.org/pdf/2401.09416)

* Collaborative Control for Geometry-Conditioned PBR Image Generation (Arxiv'24) [[Project]](https://unity-research.github.io/holo-gen/) [[Paper]](https://github.com/unity-research/holo-gen/releases/download/paper/paper.pdf)

* Single Mesh Diffusion Models with Field Latents for Texture Generation (CVPR'24) [[Project]](https://single-mesh-diffusion.github.io/) [[Paper]](https://arxiv.org/pdf/2312.09250) [[Code]](https://github.com/google-research/google-research/tree/master/mesh_diffusion)

* Paint3D: Paint Anything 3D with Lighting-Less Texture Diffusion Models (Arxiv'23) [[Project]](https://paint3d.github.io/) [[Paper]](https://arxiv.org/pdf/2312.13913) [[Code]](https://github.com/OpenTexture/Paint3D)

* Text-Guided Texturing by Synchronized Multi-View Diffusion (Arxiv'23) [[Paper]](https://arxiv.org/pdf/2311.12891) [[Code]](https://github.com/LIU-Yuxin/SyncMVD)

* Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation (ICCV'23) [[Project]](https://fantasia3d.github.io/) [[Paper]](https://fantasia3d.github.io/assets/Fantasia3D.pdf) [[Code]](https://github.com/Gorilla-Lab-SCUT/Fantasia3D)

* TexFusion: Synthesizing 3D Textures with Text-Guided Image Diffusion Models (ICCV'23) [[Project]](https://research.nvidia.com/labs/toronto-ai/texfusion/) [[Paper]](https://research.nvidia.com/labs/toronto-ai/texfusion/static/iccv2023_texfusion.pdf)

* Text2Tex: Text-driven Texture Synthesis via Diffusion Models (ICCV'23) [[Project]](https://daveredrum.github.io/Text2Tex/) [[Paper]](https://daveredrum.github.io/Text2Tex/static/Text2Tex.pdf) [[Code]](https://github.com/daveredrum/Text2Tex)

* TEXTure: Text-Guided Texturing of 3D Shapes (SIGGRAPH'23) [[Project]](https://texturepaper.github.io/TEXTurePaper/) [[Paper]](https://arxiv.org/pdf/2302.01721) [[Code]](https://github.com/TEXTurePaper/TEXTurePaper)

* Text2Mesh: Text-Driven Neural Stylization for Meshes (CVPR'22) [[Porject]](https://threedle.github.io/text2mesh/) [[Paper]](https://arxiv.org/pdf/2112.03221) [[Code]](https://github.com/threedle/text2mesh)

## Room Scale

### Mesh Design

* AnyHome: Open-Vocabulary Generation of Structured and Textured 3D Homes (Arxiv'24) [[Project]](https://freddierao.github.io/AnyHome/) [[Paper]](https://arxiv.org/pdf/2312.06644) [[Code]](https://github.com/FreddieRao/anyhome_github)

* Frankenstein: Generating Semantic-Compositional 3D Scenes in One Tri-Plane (Arxiv'24) [[Paper]](https://arxiv.org/pdf/2403.16210)

* External Knowledge Enhanced 3D Scene Generation from Sketch (Arxiv'24) [[Paper]](https://arxiv.org/pdf/2403.14121)

* DreamScene360: Unconstrained Text-to-3D Scene Generation with Panoramic Gaussian Splatting (Arxiv'24) [[Project]](https://dreamscene360.github.io/) [[Paper]](https://arxiv.org/pdf/2404.06903)

* Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models (ICCV'23) [[Project]](https://lukashoel.github.io/text-to-room/) [[Paper]](https://lukashoel.github.io/text-to-room/static/images/Text2Room.pdf) [[Code]](https://github.com/lukasHoel/text2room)

* SceneWiz3D: Towards Text-guided 3D Scene Composition (Arxiv'23) [[Project]](https://zqh0253.github.io/SceneWiz3D/) [[Paper]](https://zqh0253.github.io/SceneWiz3D/media/scenewiz3d.pdf) [[Code]](https://github.com/zqh0253/SceneWiz3D)

* Ctrl-Room: Controllable Text-to-3D Room Meshes Generation with Layout Constraints (Arxiv'23) [[Paper]](https://arxiv.org/pdf/2310.03602v1)

### Parametric Design

* Language Guided Generation of 3D Embodied AI Environments (CVPR'24) [[Project]](https://yueyang1996.github.io/holodeck/) [[Paper]](https://yueyang1996.github.io/papers/holodeck.pdf) [[Code]](https://github.com/allenai/Holodeck)

* DiffuScene: Denoising Diffusion Models for Generative Indoor Scene Synthesis (CVPR'24) [[Project]](https://tangjiapeng.github.io/projects/DiffuScene/) [[Paper]](https://arxiv.org/pdf/2303.14207) [[Code]](https://github.com/tangjiapeng/DiffuScene?tab=readme-ov-file)

* InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior (ICLR'24) [[Project]](https://chenguolin.github.io/projects/InstructScene/) [[Paper]](https://arxiv.org/pdf/2402.04717) [[Code]](https://github.com/chenguolin/InstructScene)

* Open-Universe Indoor Scene Generation using LLM Program Synthesis and Uncurated Object Databases (Arxiv'24) [[Paper]](https://arxiv.org/pdf/2403.09675)

* I-Design: Personalized LLM Interior Designer (Arxiv'24) [[Project]](https://atcelen.github.io/I-Design/) [[Paper]](https://arxiv.org/pdf/2404.02838)

* LayoutGPT: Compositional Visual Planning and Generation with Large Language Models (NeurIPS'23) [[Project]](https://layoutgpt.github.io/) [[Paper]](https://arxiv.org/pdf/2305.15393) [[Code]](https://github.com/weixi-feng/LayoutGPT)
  
### Texture Design

* DreamSpace: Dreaming Your Room Space with Text-Driven Panoramic Texture Propagation (VR'24) [[Project]](https://ybbbbt.com/publication/dreamspace/) [[Paper]](https://ybbbbt.com/publication/dreamspace/media/DreamSpace.pdf) [[Code]](https://github.com/ybbbbt/dreamspace)

* SceneTex: High-Quality Texture Synthesis for Indoor Scenes via Diffusion Priors (CVPR'24) [[Project]](https://daveredrum.github.io/SceneTex/) [[Paper]](https://daveredrum.github.io/SceneTex/static/SceneTex.pdf) [[Code]](https://github.com/daveredrum/SceneTex)

* MVDiffusion: Enabling Holistic Multi-view Image Generation with Correspondence-Aware Diffusion (NeurIPS'23) [[Project]](https://mvdiffusion.github.io/) [[Paper]](https://mvdiffusion.github.io/assets/mvdiffusion_paper.pdf) [[Code]](https://github.com/Tangshitao/MVDiffusion)

* Text2Scene: Text-Driven Indoor Scene Stylization With Part-Aware Details (CVPR'23) [[Paper]](https://arxiv.org/pdf/2308.16880)

## City Scale

### Mesh Design

* XCube: Large-Scale 3D Generative Modeling using Sparse Voxel Hierarchies (CVPR'24 highlight) [[Project]](https://research.nvidia.com/labs/toronto-ai/xcube/) [[Paper]](https://research.nvidia.com/labs/toronto-ai/xcube/assets/paper.pdf)

* Sat2Scene: 3D Urban Scene Generation from Satellite Images with Diffusion (CVPR'24 highlight) [[Project]](https://shinkyo0513.github.io/Sat2Scene/) [[Paper]](https://arxiv.org/pdf/2401.10786) [[Code]](https://github.com/shinkyo0513/Sat2Scene)

* WonderJourney: Going from Anywhere to Everywhere (CVPR'24) [[Project]](https://kovenyu.com/wonderjourney/) [[Paper]](https://arxiv.org/pdf/2312.03884) [[Code]](https://github.com/KovenYu/WonderJourney)

* BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation (Arxiv'24) [[Paper]](https://arxiv.org/pdf/2401.17053)

### Parametric Design

* CityDreamer: Compositional Generative Model of Unbounded 3D Cities (CVPR'24) [[Project]](https://www.infinitescript.com/project/city-dreamer/) [[Paper]](https://arxiv.org/pdf/2309.00610) [[Code]](https://github.com/hzxie/CityDreamer)

* SceneX: Procedural Controllable Large-scale Scene Generation via Large-language Models (Arxiv'24) [[Project]](https://scenex-lab.github.io/) [[Paper]](https://arxiv.org/pdf/2403.15698) [[Code]](https://github.com/SceneX-LAB/SceneX-LAB)

* Infinite Photorealistic Worlds using Procedural Generation (CVPR'23) [[Project]](https://infinigen.org/) [[Paper]](https://arxiv.org/pdf/2306.09310) [[Code]](https://github.com/princeton-vl/infinigen)
